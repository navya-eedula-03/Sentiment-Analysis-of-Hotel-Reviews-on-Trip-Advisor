{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4768 entries, 0 to 4767\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Review_Text  4763 non-null   object\n",
      " 1   Sentiment    4766 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 74.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Read the data from CSV files\n",
    "temp = pd.read_csv('../For_preprocessing.csv')\n",
    "temp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=temp.dropna(subset=['Review_Text'])\n",
    "temp=temp.dropna(subset=['Sentiment'])\n",
    "temp = temp.reset_index(drop=True)\n",
    "\n",
    "temp_val = temp['Sentiment'].tolist()\n",
    "#len(temp_val)\n",
    "ind_list = []\n",
    "\n",
    "for i in range(len(temp['Sentiment'])):\n",
    "    if temp_val[i] != '1' and temp_val[i] != '2' and temp_val[i] != '3':\n",
    "        ind_list.append(i)\n",
    "        \n",
    "temp.reset_index(drop=True)\n",
    "temp.drop(temp.index[ind_list], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4699 entries, 0 to 4698\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Review_Text  4699 non-null   object\n",
      " 1   Sentiment    4699 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 73.5+ KB\n"
     ]
    }
   ],
   "source": [
    "temp = temp.reset_index(drop=True)\n",
    "temp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1', '2', '3'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = temp['Sentiment'].tolist()\n",
    "st=set(st)\n",
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to normalise hotel ratings in the range of -1 to 1\n",
    "\n",
    "# def change_labels(r):\n",
    "#     if(r=='1'):\n",
    "#         return '0'\n",
    "#     if(r=='2'):\n",
    "#         return '1'\n",
    "#     if(r=='3'):\n",
    "#         return '2' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp['Sentiment'] = temp['Sentiment'].apply(lambda x:change_labels(x))\n",
    "# temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_val = temp['Sentiment'].tolist()\n",
    "#len(temp_val)\n",
    "ind_list = []\n",
    "\n",
    "for i in range(len(temp['Sentiment'])):\n",
    "    if temp_val[i] != '1' and temp_val[i] != '2' and temp_val[i] != '3':\n",
    "        ind_list.append(i)\n",
    "temp.reset_index(drop=True)\n",
    "temp.drop(temp.index[ind_list], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper3 = {\"1\":0, \"2\":1, \"3\":2}\n",
    "temp['Sentiment'] = temp['Sentiment'].replace(scale_mapper3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4699 entries, 0 to 4698\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Review_Text  4699 non-null   object\n",
      " 1   Sentiment    4699 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 73.5+ KB\n"
     ]
    }
   ],
   "source": [
    "temp = temp.reset_index(drop=True)\n",
    "temp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Its really nice place to stay especially for b...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It seems that hotel does not check the basic a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Worst hotel I have ever encountered. I will ne...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Had a good time in this hotel and the staff Ku...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good hotel and staff Veg food good non veg bre...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4694</th>\n",
       "      <td>My fifth stay at the hotel for business. Rooms...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4695</th>\n",
       "      <td>enjoyable</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4696</th>\n",
       "      <td>Most impressive service by staff in all areas....</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4697</th>\n",
       "      <td>The linens were smelling bad, and the elevator...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4698</th>\n",
       "      <td>Stayed at the Hyatt in Chennai for the first t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4699 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Review_Text  Sentiment\n",
       "0     Its really nice place to stay especially for b...          2\n",
       "1     It seems that hotel does not check the basic a...          0\n",
       "2     Worst hotel I have ever encountered. I will ne...          0\n",
       "3     Had a good time in this hotel and the staff Ku...          2\n",
       "4     good hotel and staff Veg food good non veg bre...          2\n",
       "...                                                 ...        ...\n",
       "4694  My fifth stay at the hotel for business. Rooms...          2\n",
       "4695                                          enjoyable          2\n",
       "4696  Most impressive service by staff in all areas....          2\n",
       "4697  The linens were smelling bad, and the elevator...          0\n",
       "4698  Stayed at the Hyatt in Chennai for the first t...          2\n",
       "\n",
       "[4699 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_reg():\n",
    "    temp['Review_Text'] = temp['Review_Text'].replace(r'http\\S+','',regex=True).replace(r'www\\S+','',regex=True).replace(r'\\d+','',regex=True)\n",
    "    tokens = RegexpTokenizer(r'\\w+')\n",
    "    temp['Review_Text']=temp['Review_Text'].apply(lambda x:tokens.tokenize(x.lower()))\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    stop_words = stop_words.union(\",\",\"(\",\")\",\"[\",\"]\",\"{\",\"}\",\"#\",\"@\",\"!\",\":\",\";\",\".\",\"?\")\n",
    "    temp['Review_Text'] = temp['Review_Text'].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "tokenize_reg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lem = WordNetLemmatizer()\n",
    "def lemm(text):\n",
    "    sent=[]\n",
    "    for word in text:\n",
    "        sent.append(lem.lemmatize(word))\n",
    "    return sent\n",
    "\n",
    "ps=PorterStemmer()\n",
    "\n",
    "def stemm(text):        \n",
    "    sent = []\n",
    "    for word in text:\n",
    "        sent.append(ps.stem(word))\n",
    "    return sent\n",
    "\n",
    "temp['Review_Text'] =  temp.apply(lambda x: stemm(lemm(x['Review_Text'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revs=temp['Review_Text'].tolist()\n",
    "for i in range(len(revs)):\n",
    "    revs[i]=' '.join(revs[i])\n",
    "temp['Review_Text'] = revs\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_numeric(temp['Sentiment'])\n",
    "st = temp['Sentiment'].tolist()\n",
    "st=set(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', XGBClassifier(use_label_encoder=False,\n",
    "                                  eval_metric='mlogloss'))])\n",
    "\n",
    "tuned_parameters = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__min_child_weight': [1, 5, 10],\n",
    "        'clf__gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'clf__subsample': [0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "        'clf__colsample_bytree': [0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "        'clf__max_depth': [3, 4, 5,6,8,10,12, 14, 16],\n",
    "        'clf__learning_rate': [1, 1e-1, 1e-2, 0.3],\n",
    "        'clf__booster': ['gbtree','dart'],\n",
    "        #'n_estimators' : [300,500,600],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(temp['Review_Text'], temp['Sentiment'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix, classification_report,accuracy_score\n",
    "\n",
    "# score = 'f1_macro'\n",
    "# print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "# print()\n",
    "# np.errstate(divide='ignore')\n",
    "# clf = GridSearchCV(text_clf, tuned_parameters, cv=10, scoring=score)\n",
    "# clf.fit(x_train, y_train)\n",
    "\n",
    "# print(\"Best parameters set found on development set:\")\n",
    "# print()\n",
    "# print(clf.best_params_)\n",
    "# print()\n",
    "# print(\"Grid scores on development set:\")\n",
    "# print()\n",
    "# for mean, std, params in zip(clf.cv_results_['mean_test_score'], \n",
    "#                              clf.cv_results_['std_test_score'], \n",
    "#                              clf.cv_results_['params']):\n",
    "#     print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "# print()\n",
    "\n",
    "# print(\"Detailed classification report:\")\n",
    "# print()\n",
    "# print(\"The model is trained on the full development set.\")\n",
    "# print(\"The scores are computed on the full evaluation set.\")\n",
    "# print()\n",
    "# print(classification_report(y_test, clf.predict(x_test), digits=4))\n",
    "# print()\n",
    "# print (\"Confusion Matrix\")\n",
    "# print(confusion_matrix(y_test, clf.predict(x_test)))\n",
    "# print(\"Accuracy Score\")\n",
    "# print(accuracy_score(y_test, clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A total number of combinations for the set of parameters above is a product of options for each parameter (3 x 5 x 3 x 3 x 3 = 405). It also needs to be multiplied by 5 to calculate a total number of data-fitting runs as we will be doing 5-fold cross-validation. That gets to be a large number in a hurry if you are using many parameters and lots of options, which is why brute-force grid search takes a long time.\n",
    "\n",
    "Next we set up our classifier. We use sklearn's API of XGBoost as that is a requirement for grid search (another reason why Bayesian optimization may be preferable, as it does not need to be sklearn-wrapped). You should consider setting a learning rate to smaller value (at least 0.01, if not even lower), or make it a hyperparameter for grid searching. I am not using very small value here to save on running time.\n",
    "\n",
    "Even though we have 4 threads available per job on Kaggle, I think it is more efficient to do XGBoost runs on single threads, but instead run 4 parallel jobs in the grid search. It's up to you whether you want to change this.\n",
    "\n",
    "\n",
    "Next we set up our stratified folds and grid search parameters. I am using AUC as a scoring function, but you can plug in a custom scoring function here if you wish. Grid search wil spawn 4 jobs running a single thread each. The param_comb parameter declares how many different combinations should be picked randomly out of our total (405, see above). I am doing only 5 here, knowing that it will not properly sample the parameter space. Definitely use a bigger number for param_comb.\n",
    "\n",
    "You may want to increase/decrease verbosity depending on your preference.\n",
    "\n",
    "Note that I have set the number of splits/folds to 3 in order to save time. You should probably put 5 there to get a more reliable result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from timeit import Timer\n",
    "\n",
    "folds = 10\n",
    "param_comb = 10\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n",
    "\n",
    "random_search = RandomizedSearchCV(text_clf, param_distributions=tuned_parameters, n_iter=param_comb, n_jobs=4, cv=skf.split(x_train, y_train), verbose=3, random_state=1001 )\n",
    "\n",
    "# # Here we go\n",
    "# start_time = Timer(None) # timing starts from this point for \"start_time\" variable\n",
    "random_search.fit(x_train, y_train)\n",
    "# Timer(start_time) # timing ends here for \"start_time\" variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n All results:')\n",
    "print(random_search.cv_results_)\n",
    "print('\\n Best estimator:')\n",
    "print(random_search.best_estimator_)\n",
    "print('\\n Best score:')\n",
    "print(random_search.best_score_)\n",
    "print('\\n Best normalized gini score for %d-fold search with %d parameter combinations:' % (folds, param_comb))\n",
    "print(random_search.best_score_ * 2 - 1)\n",
    "print('\\n Best hyperparameters:')\n",
    "print(random_search.best_params_)\n",
    "# results = pd.DataFrame(random_search.cv_results_)\n",
    "# results.to_csv('xgb-random-grid-search-results-01.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wo_hyp_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', XGBClassifier())])\n",
    "\n",
    "wo_hyp_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "print(classification_report(y_test, wo_hyp_clf.predict(x_test), digits=4))\n",
    "print()\n",
    "print (\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, wo_hyp_clf.predict(x_test)))\n",
    "print(\"Accuracy Score\")\n",
    "print(accuracy_score(y_test, wo_hyp_clf.predict(x_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'vect__ngram_range': (1, 2), 'tfidf__use_idf': False, 'tfidf__norm': 'l2', 'clf__subsample': 1.0, 'clf__min_child_weight': 5, 'clf__max_depth': 5, 'clf__gamma': 0.5, 'clf__colsample_bytree': 0.6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf = Pipeline([('vect', CountVectorizer(ngram_range= (1, 2))),\n",
    "                     ('tfidf', TfidfTransformer(use_idf= False, norm= 'l2')),\n",
    "                     ('clf', XGBClassifier(use_label_encoder=False,\n",
    "                                  eval_metric='mlogloss', subsample= 1.0, min_child_weight= 1, max_depth= 4, learning_rate = 1, gamma= 0.5, colsample_bytree= 0.6, booster = 'gbtree'))])\n",
    "best_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "print(classification_report(y_test, best_clf.predict(x_test), digits=4))\n",
    "print()\n",
    "print (\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, best_clf.predict(x_test)))\n",
    "print(\"Accuracy Score\")\n",
    "print(accuracy_score(y_test, best_clf.predict(x_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conslusion\n",
    "The model, which was trained on the development set, demonstrated $F_1=0.765$ on the evaluation set.\n",
    "\n",
    "## References\n",
    "1. Y. Rubtsova, \"Constructing a Corpus for Sentiment Classification Training\", Software & Systems, vol. 109, no. 1, pp. 72-78, 2015. \n",
    "2. \"Naive Bayes\", scikit-learn.org, 2018. [Online]. Available: http://scikit-learn.org/stable/modules/naive_bayes.html. [Accessed: 26- Aug- 2018]. \n",
    "3. \"Working With Text Data\", scikit-learn.org, 2018. [Online]. Available: http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html. [Accessed: 26- Aug- 2018]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
