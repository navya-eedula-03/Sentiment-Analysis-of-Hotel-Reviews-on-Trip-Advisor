{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "trailing comma not allowed without surrounding parentheses (<ipython-input-38-f776a63a5f17>, line 44)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-38-f776a63a5f17>\"\u001b[1;36m, line \u001b[1;32m44\u001b[0m\n\u001b[1;33m    from sklearn.metrics import confusion_matrix, classification_report,\u001b[0m\n\u001b[1;37m                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m trailing comma not allowed without surrounding parentheses\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import sys\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from pprint import pprint\n",
    "from functools import reduce\n",
    "from matplotlib import pyplot as plt\n",
    "import string\n",
    "\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import KFold\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "from tabulate import tabulate\n",
    "import argparse\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report,\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4768 entries, 0 to 4767\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Review_Text  4763 non-null   object\n",
      " 1   Sentiment    4766 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 74.6+ KB\n"
     ]
    }
   ],
   "source": [
    "temp = pd.read_csv('For_preprocessing.csv')\n",
    "temp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Its really nice place to stay especially for b...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It seems that hotel does not check the basic a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Worst hotel I have ever encountered. I will ne...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Had a good time in this hotel and the staff Ku...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good hotel and staff Veg food good non veg bre...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4763</th>\n",
       "      <td>My fifth stay at the hotel for business. Rooms...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4764</th>\n",
       "      <td>enjoyable</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4765</th>\n",
       "      <td>Most impressive service by staff in all areas....</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4766</th>\n",
       "      <td>The linens were smelling bad, and the elevator...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4767</th>\n",
       "      <td>Stayed at the Hyatt in Chennai for the first t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4768 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Review_Text Sentiment\n",
       "0     Its really nice place to stay especially for b...         3\n",
       "1     It seems that hotel does not check the basic a...         1\n",
       "2     Worst hotel I have ever encountered. I will ne...         1\n",
       "3     Had a good time in this hotel and the staff Ku...         3\n",
       "4     good hotel and staff Veg food good non veg bre...         3\n",
       "...                                                 ...       ...\n",
       "4763  My fifth stay at the hotel for business. Rooms...         3\n",
       "4764                                          enjoyable         3\n",
       "4765  Most impressive service by staff in all areas....         3\n",
       "4766  The linens were smelling bad, and the elevator...         1\n",
       "4767  Stayed at the Hyatt in Chennai for the first t...         3\n",
       "\n",
       "[4768 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=temp.dropna(subset=['Review_Text'])\n",
    "temp=temp.dropna(subset=['Sentiment'])\n",
    "temp = temp.reset_index(drop=True)\n",
    "temp_val = temp['Sentiment'].tolist()\n",
    "#len(temp_val)\n",
    "ind_list = []\n",
    "\n",
    "for i in range(len(temp['Sentiment'])):\n",
    "    if temp_val[i] != '1' and temp_val[i] != '2' and temp_val[i] != '3':\n",
    "        ind_list.append(i)\n",
    "temp.reset_index(drop=True)\n",
    "temp.drop(temp.index[ind_list], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(temp['Sentiment'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4699 entries, 0 to 4698\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Review_Text  4699 non-null   object\n",
      " 1   Sentiment    4699 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 73.5+ KB\n"
     ]
    }
   ],
   "source": [
    "temp = temp.reset_index(drop=True)\n",
    "temp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(tweet):\n",
    "    \n",
    "    #Generating the list of words in the tweet (punctuations removed)\n",
    "    def form_sentence(tweet):\n",
    "        tweet_blob = TextBlob(tweet)\n",
    "        return ' '.join(tweet_blob.words)\n",
    "    new_tweet = form_sentence(tweet)\n",
    "    \n",
    "    #Removing stopwords and words with unusual symbols\n",
    "    def no_user_alpha(tweet):\n",
    "        tweet_list = [ele for ele in tweet.split()]\n",
    "        clean_tokens = [t for t in tweet_list if re.match(r'[^\\W\\d]*$', t)]\n",
    "        clean_s = ' '.join(clean_tokens)\n",
    "        clean_mess = [word for word in clean_s.split() if word.lower() not in stopwords.words('english')]\n",
    "        return clean_mess\n",
    "    no_punc_tweet = no_user_alpha(new_tweet)\n",
    "    \n",
    "    #Normalizing the words in tweets \n",
    "    def normalization(tweet_list):\n",
    "        lem = WordNetLemmatizer()\n",
    "        normalized_tweet = []\n",
    "        for word in tweet_list:\n",
    "            normalized_text = lem.lemmatize(word,'v')\n",
    "            normalized_tweet.append(normalized_text)\n",
    "        return normalized_tweet\n",
    "    \n",
    "    \n",
    "    return normalization(no_punc_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_reg():\n",
    "    temp['Review_Text'] = temp['Review_Text'].replace(r'http\\S+','',regex=True).replace(r'www\\S+','',regex=True).replace(r'\\d+','',regex=True)\n",
    "    tokens = RegexpTokenizer(r'\\w+')\n",
    "    temp['Review_Text']=temp['Review_Text'].apply(lambda x:tokens.tokenize(x.lower()))\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    stop_words = stop_words.union(\",\",\"(\",\")\",\"[\",\"]\",\"{\",\"}\",\"#\",\"@\",\"!\",\":\",\";\",\".\",\"?\")\n",
    "    temp['Review_Text'] = temp['Review_Text'].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "tokenize_reg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "lem = WordNetLemmatizer()\n",
    "def lemm(text):\n",
    "    sent=[]\n",
    "    for word in text:\n",
    "        sent.append(lem.lemmatize(word))\n",
    "    return sent\n",
    "\n",
    "ps=PorterStemmer()\n",
    "\n",
    "def stemm(text):        \n",
    "    sent = []\n",
    "    for word in text:\n",
    "        sent.append(ps.stem(word))\n",
    "    return sent\n",
    "\n",
    "temp['Review_Text'] =  temp.apply(lambda x: stemm(lemm(x['Review_Text'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>realli nice place stay especi busi tourist purpos</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seem hotel check basic amen room hand room tra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>worst hotel ever encount never think stay thii...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good time hotel staff kumar aishwarya hous kee...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good hotel staff veg food good non veg breakfa...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4694</th>\n",
       "      <td>fifth stay hotel busi room great restaur excel...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4695</th>\n",
       "      <td>enjoy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4696</th>\n",
       "      <td>impress servic staff area good restaur fit cen...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4697</th>\n",
       "      <td>linen smell bad elev pungent odour housekeep p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4698</th>\n",
       "      <td>stay hyatt chennai first time refresh chang ho...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4699 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Review_Text Sentiment\n",
       "0     realli nice place stay especi busi tourist purpos         3\n",
       "1     seem hotel check basic amen room hand room tra...         1\n",
       "2     worst hotel ever encount never think stay thii...         1\n",
       "3     good time hotel staff kumar aishwarya hous kee...         3\n",
       "4     good hotel staff veg food good non veg breakfa...         3\n",
       "...                                                 ...       ...\n",
       "4694  fifth stay hotel busi room great restaur excel...         3\n",
       "4695                                              enjoy         3\n",
       "4696  impress servic staff area good restaur fit cen...         3\n",
       "4697  linen smell bad elev pungent odour housekeep p...         1\n",
       "4698  stay hyatt chennai first time refresh chang ho...         3\n",
       "\n",
       "[4699 rows x 2 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revs=temp['Review_Text'].tolist()\n",
    "for i in range(len(revs)):\n",
    "    revs[i]=' '.join(revs[i])\n",
    "temp['Review_Text'] = revs\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = temp['Sentiment'].tolist()\n",
    "st=set(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1', '2', '3'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('realli', 3140),\n",
       " ('nice', 2592),\n",
       " ('place', 2895),\n",
       " ('stay', 3691),\n",
       " ('especi', 1295),\n",
       " ('busi', 537),\n",
       " ('tourist', 3972),\n",
       " ('purpos', 3061),\n",
       " ('seem', 3415),\n",
       " ('hotel', 1837),\n",
       " ('check', 645),\n",
       " ('basic', 347),\n",
       " ('amen', 138),\n",
       " ('room', 3306),\n",
       " ('hand', 1713),\n",
       " ('travel', 3996),\n",
       " ('phone', 2873),\n",
       " ('work', 4308),\n",
       " ('creat', 921),\n",
       " ('problem', 3020),\n",
       " ('hectic', 1752),\n",
       " ('day', 987),\n",
       " ('would', 4322),\n",
       " ('like', 2217),\n",
       " ('relax', 3199),\n",
       " ('pace', 2761),\n",
       " ('send', 3424),\n",
       " ('technician', 3849),\n",
       " ('keep', 2077),\n",
       " ('look', 2262),\n",
       " ('fix', 1452),\n",
       " ('hour', 1844),\n",
       " ('get', 1603),\n",
       " ('chang', 626),\n",
       " ('worst', 4318),\n",
       " ('ever', 1306),\n",
       " ('encount', 1261),\n",
       " ('never', 2576),\n",
       " ('think', 3903),\n",
       " ('thii', 3899),\n",
       " ('futur', 1567),\n",
       " ('good', 1636),\n",
       " ('time', 3936),\n",
       " ('staff', 3666),\n",
       " ('kumar', 2139),\n",
       " ('aishwarya', 95),\n",
       " ('hous', 1846),\n",
       " ('guy', 1695),\n",
       " ('sure', 3784),\n",
       " ('name', 2531),\n",
       " ('peopl', 2846),\n",
       " ('make', 2319),\n",
       " ('pleasant', 2908),\n",
       " ('happi', 1723),\n",
       " ('back', 306),\n",
       " ('chennai', 653),\n",
       " ('job', 2037),\n",
       " ('veg', 4163),\n",
       " ('food', 1487),\n",
       " ('non', 2611),\n",
       " ('breakfast', 492),\n",
       " ('need', 2558),\n",
       " ('improv', 1904),\n",
       " ('great', 1664),\n",
       " ('welcom', 4264),\n",
       " ('help', 1756),\n",
       " ('alway', 128),\n",
       " ('mostli', 2486),\n",
       " ('clean', 708),\n",
       " ('bathroom', 352),\n",
       " ('care', 572),\n",
       " ('first', 1447),\n",
       " ('hot', 1834),\n",
       " ('water', 4245),\n",
       " ('second', 3408),\n",
       " ('one', 2696),\n",
       " ('take', 3813),\n",
       " ('long', 2258),\n",
       " ('drain', 1169),\n",
       " ('tub', 4017),\n",
       " ('plu', 2915),\n",
       " ('paint', 2768),\n",
       " ('caulk', 597),\n",
       " ('peel', 2840),\n",
       " ('wall', 4224),\n",
       " ('point', 2921),\n",
       " ('restaur', 3258),\n",
       " ('excel', 1328),\n",
       " ('custom', 963),\n",
       " ('servic', 3439),\n",
       " ('awesom', 289),\n",
       " ('luxuri', 2293),\n",
       " ('friendli', 1540),\n",
       " ('comfort', 769),\n",
       " ('polit', 2926),\n",
       " ('brick', 496),\n",
       " ('oven', 2744),\n",
       " ('chef', 651),\n",
       " ('extrem', 1369),\n",
       " ('meal', 2383),\n",
       " ('advertis', 65),\n",
       " ('recommend', 3162),\n",
       " ('overal', 2745),\n",
       " ('best', 406),\n",
       " ('experi', 1350),\n",
       " ('decent', 999),\n",
       " ('price', 2993),\n",
       " ('trip', 4009),\n",
       " ('two', 4027),\n",
       " ('find', 1440),\n",
       " ('perfect', 2850),\n",
       " ('cleanli', 711),\n",
       " ('locat', 2242),\n",
       " ('also', 121),\n",
       " ('valu', 4149),\n",
       " ('money', 2475),\n",
       " ('suggest', 3763),\n",
       " ('offer', 2666),\n",
       " ('least', 2191),\n",
       " ('includ', 1911),\n",
       " ('case', 584),\n",
       " ('singl', 3515),\n",
       " ('occup', 2653),\n",
       " ('doubl', 1162),\n",
       " ('deal', 993),\n",
       " ('nagar', 2526),\n",
       " ('close', 727),\n",
       " ('shop', 3478),\n",
       " ('hub', 1851),\n",
       " ('cult', 949),\n",
       " ('south', 3603),\n",
       " ('indian', 1923),\n",
       " ('saravana', 3364),\n",
       " ('murugan', 2511),\n",
       " ('spaciou', 3610),\n",
       " ('well', 4265),\n",
       " ('light', 2215),\n",
       " ('courteou', 904),\n",
       " ('simpl', 3510),\n",
       " ('min', 2429),\n",
       " ('process', 3023),\n",
       " ('complimentari', 801),\n",
       " ('pick', 2882),\n",
       " ('drop', 1184),\n",
       " ('airport', 92),\n",
       " ('thing', 3902),\n",
       " ('add', 46),\n",
       " ('certainli', 617),\n",
       " ('increas', 1917),\n",
       " ('recept', 3151),\n",
       " ('otherwis', 2729),\n",
       " ('noth', 2624),\n",
       " ('bad', 311),\n",
       " ('super', 3773),\n",
       " ('enjoy', 1269),\n",
       " ('neg', 2562),\n",
       " ('right', 3284),\n",
       " ('smooth', 3557),\n",
       " ('rememb', 3209),\n",
       " ('resid', 3244),\n",
       " ('zodiac', 4358),\n",
       " ('better', 409),\n",
       " ('heart', 1745),\n",
       " ('district', 1133),\n",
       " ('easili', 1214),\n",
       " ('access', 18),\n",
       " ('mode', 2458),\n",
       " ('difficulti', 1083),\n",
       " ('understand', 4058),\n",
       " ('english', 1267),\n",
       " ('rest', 3255),\n",
       " ('tabl', 3804),\n",
       " ('chair', 620),\n",
       " ('pc', 2831),\n",
       " ('lan', 2156),\n",
       " ('cabl', 551),\n",
       " ('much', 2504),\n",
       " ('dust', 1198),\n",
       " ('wifi', 4287),\n",
       " ('internet', 1974),\n",
       " ('speed', 3622),\n",
       " ('bar', 337),\n",
       " ('waiter', 4219),\n",
       " ('serv', 3435),\n",
       " ('tandoori', 3822),\n",
       " ('chicken', 664),\n",
       " ('salti', 3351),\n",
       " ('friend', 1539),\n",
       " ('accord', 26),\n",
       " ('rate', 3124),\n",
       " ('star', 3681),\n",
       " ('continu', 855),\n",
       " ('topper', 3964),\n",
       " ('visit', 4204),\n",
       " ('famili', 1388),\n",
       " ('appear', 190),\n",
       " ('checkout', 649),\n",
       " ('provid', 3042),\n",
       " ('sinc', 3512),\n",
       " ('small', 3547),\n",
       " ('luggag', 2289),\n",
       " ('suitabl', 3765),\n",
       " ('japan', 2023),\n",
       " ('quantiti', 3072),\n",
       " ('worth', 4319),\n",
       " ('neat', 2552),\n",
       " ('etc', 1297),\n",
       " ('central', 611),\n",
       " ('area', 210),\n",
       " ('lot', 2270),\n",
       " ('option', 2714),\n",
       " ('eat', 1217),\n",
       " ('tast', 3831),\n",
       " ('qualiti', 3071),\n",
       " ('could', 894),\n",
       " ('build', 526),\n",
       " ('level', 2208),\n",
       " ('spend', 3627),\n",
       " ('thank', 3885),\n",
       " ('offici', 2669),\n",
       " ('facil', 1377),\n",
       " ('everyth', 1311),\n",
       " ('fine', 1441),\n",
       " ('spread', 3647),\n",
       " ('situat', 3523),\n",
       " ('prime', 3002),\n",
       " ('easi', 1212),\n",
       " ('connect', 835),\n",
       " ('group', 1677),\n",
       " ('citi', 696),\n",
       " ('book', 469),\n",
       " ('mani', 2335),\n",
       " ('spoil', 3640),\n",
       " ('choic', 675),\n",
       " ('loung', 2276),\n",
       " ('terrac', 3871),\n",
       " ('view', 4190),\n",
       " ('rent', 3218),\n",
       " ('cab', 550),\n",
       " ('charg', 633),\n",
       " ('regular', 3193),\n",
       " ('free', 1523),\n",
       " ('wi', 4283),\n",
       " ('fi', 1432),\n",
       " ('ok', 2676),\n",
       " ('howev', 1848),\n",
       " ('timetaken', 3937),\n",
       " ('resond', 3248),\n",
       " ('poor', 2936),\n",
       " ('menu', 2400),\n",
       " ('daili', 970),\n",
       " ('toiletri', 3954),\n",
       " ('towel', 3974),\n",
       " ('replenish', 3231),\n",
       " ('insuffici', 1961),\n",
       " ('fantast', 1394),\n",
       " ('profession', 3025),\n",
       " ('three', 3914),\n",
       " ('insid', 1950),\n",
       " ('plenti', 2913),\n",
       " ('varieti', 4156),\n",
       " ('perhap', 2853),\n",
       " ('almost', 113),\n",
       " ('sell', 3419),\n",
       " ('durat', 1196),\n",
       " ('ask', 235),\n",
       " ('k', 2054),\n",
       " ('without', 4297),\n",
       " ('even', 1303),\n",
       " ('complementari', 797),\n",
       " ('bottl', 477),\n",
       " ('wow', 4323),\n",
       " ('wife', 4286),\n",
       " ('januari', 2021),\n",
       " ('front', 1546),\n",
       " ('offic', 2668),\n",
       " ('everi', 1307),\n",
       " ('turn', 4022),\n",
       " ('adequ', 51),\n",
       " ('person', 2862),\n",
       " ('ideal', 1876),\n",
       " ('activ', 40),\n",
       " ('physic', 2877),\n",
       " ('quit', 3088),\n",
       " ('larg', 2163),\n",
       " ('lobbi', 2239),\n",
       " ('littl', 2231),\n",
       " ('detract', 1061),\n",
       " ('safe', 3337),\n",
       " ('malfunct', 2324),\n",
       " ('leave', 2194),\n",
       " ('bandwidth', 331),\n",
       " ('overli', 2749),\n",
       " ('max', 2374),\n",
       " ('email', 1250),\n",
       " ('imposs', 1899),\n",
       " ('fit', 1450),\n",
       " ('joke', 2040),\n",
       " ('pillow', 2889),\n",
       " ('differ', 1080),\n",
       " ('size', 3527),\n",
       " ('dirti', 1102),\n",
       " ('stain', 3672),\n",
       " ('curtain', 959),\n",
       " ('next', 2584),\n",
       " ('bed', 378),\n",
       " ('walk', 4222),\n",
       " ('studi', 3731),\n",
       " ('slow', 3543),\n",
       " ('intern', 1972),\n",
       " ('accept', 17),\n",
       " ('discov', 1114),\n",
       " ('card', 571),\n",
       " ('maintain', 2312),\n",
       " ('extraordinari', 1368),\n",
       " ('park', 2800),\n",
       " ('desk', 1054),\n",
       " ('warm', 4230),\n",
       " ('arrang', 219),\n",
       " ('cradl', 915),\n",
       " ('month', 2477),\n",
       " ('old', 2682),\n",
       " ('babi', 304),\n",
       " ('wide', 4284),\n",
       " ('properti', 3039),\n",
       " ('bite', 434),\n",
       " ('bath', 350),\n",
       " ('toilet', 3953),\n",
       " ('white', 4280),\n",
       " ('cushion', 962),\n",
       " ('tear', 3846),\n",
       " ('shower', 3484),\n",
       " ('window', 4289),\n",
       " ('musti', 2516),\n",
       " ('smell', 3551),\n",
       " ('wait', 4218),\n",
       " ('u', 4031),\n",
       " ('visa', 4200),\n",
       " ('applic', 196),\n",
       " ('probabl', 3019),\n",
       " ('definit', 1013),\n",
       " ('cramp', 916),\n",
       " ('felt', 1422),\n",
       " ('plane', 2899),\n",
       " ('outstand', 2742),\n",
       " ('though', 3912),\n",
       " ('mainland', 2310),\n",
       " ('els', 1248),\n",
       " ('come', 765),\n",
       " ('way', 4247),\n",
       " ('near', 2546),\n",
       " ('claim', 698),\n",
       " ('disappoint', 1104),\n",
       " ('cleannessne', 713),\n",
       " ('carenessemploye', 574),\n",
       " ('restur', 3264),\n",
       " ('enough', 1271),\n",
       " ('maintainc', 2313),\n",
       " ('soon', 3590),\n",
       " ('enter', 1274),\n",
       " ('touch', 3969),\n",
       " ('anyth', 179),\n",
       " ('wors', 4317),\n",
       " ('cheap', 640),\n",
       " ('motel', 2487),\n",
       " ('want', 4228),\n",
       " ('mention', 2399),\n",
       " ('expedia', 1348),\n",
       " ('consul', 847),\n",
       " ('rather', 3125),\n",
       " ('minut', 2441),\n",
       " ('go', 1627),\n",
       " ('evn', 1316),\n",
       " ('big', 419),\n",
       " ('mall', 2325),\n",
       " ('nearbi', 2547),\n",
       " ('pool', 2935),\n",
       " ('th', 3878),\n",
       " ('floor', 1472),\n",
       " ('sever', 3445),\n",
       " ('nobodi', 2606),\n",
       " ('attend', 254),\n",
       " ('outdat', 2734),\n",
       " ('tv', 4024),\n",
       " ('counter', 897),\n",
       " ('possibl', 2954),\n",
       " ('train', 3983),\n",
       " ('attrit', 258),\n",
       " ('checkin', 647),\n",
       " ('categori', 593),\n",
       " ('terribl', 3873),\n",
       " ('layout', 2178),\n",
       " ('properli', 3038),\n",
       " ('guest', 1688),\n",
       " ('call', 556),\n",
       " ('handl', 1715),\n",
       " ('request', 3237),\n",
       " ('put', 3063),\n",
       " ('reserv', 3243),\n",
       " ('night', 2596),\n",
       " ('club', 734),\n",
       " ('dj', 1137),\n",
       " ('parti', 2803),\n",
       " ('goer', 1629),\n",
       " ('yyy', 4353),\n",
       " ('restroom', 3262),\n",
       " ('corridor', 884),\n",
       " ('pathway', 2822),\n",
       " ('morn', 2481),\n",
       " ('coupl', 900),\n",
       " ('mainten', 2315),\n",
       " ('crack', 914),\n",
       " ('seepag', 3416),\n",
       " ('manag', 2330),\n",
       " ('spruce', 3649),\n",
       " ('accommod', 23),\n",
       " ('arriv', 220),\n",
       " ('reach', 3130),\n",
       " ('advanc', 63),\n",
       " ('beauti', 371),\n",
       " ('fill', 1437),\n",
       " ('interview', 1976),\n",
       " ('cooper', 874),\n",
       " ('pro', 3016),\n",
       " ('embassi', 1252),\n",
       " ('gym', 1698),\n",
       " ('swim', 3798),\n",
       " ('con', 809),\n",
       " ('wear', 4253),\n",
       " ('prize', 3015),\n",
       " ('buffet', 519),\n",
       " ('advantag', 64),\n",
       " ('within', 4296),\n",
       " ('mile', 2427),\n",
       " ('radiu', 3099),\n",
       " ('inspir', 1952),\n",
       " ('review', 3272),\n",
       " ('write', 4325),\n",
       " ('read', 3134),\n",
       " ('tip', 3940),\n",
       " ('allow', 111),\n",
       " ('spite', 3636),\n",
       " ('payment', 2830),\n",
       " ('onlin', 2700),\n",
       " ('nearli', 2551),\n",
       " ('final', 1439),\n",
       " ('give', 1618),\n",
       " ('id', 1874),\n",
       " ('proof', 3035),\n",
       " ('yet', 4342),\n",
       " ('altern', 124),\n",
       " ('solut', 3576),\n",
       " ('equip', 1286),\n",
       " ('team', 3844),\n",
       " ('use', 4125),\n",
       " ('avail', 273),\n",
       " ('tri', 4006),\n",
       " ('renov', 3217),\n",
       " ('leak', 2186),\n",
       " ('pub', 3046),\n",
       " ('mattress', 2372),\n",
       " ('soft', 3569),\n",
       " ('pain', 2767),\n",
       " ('high', 1774),\n",
       " ('replac', 3230),\n",
       " ('must', 2515),\n",
       " ('stage', 3670),\n",
       " ('tap', 3824),\n",
       " ('leaki', 2188),\n",
       " ('health', 1741),\n",
       " ('faucet', 1402),\n",
       " ('space', 3609),\n",
       " ('opposit', 2711),\n",
       " ('forget', 1499),\n",
       " ('someth', 3582),\n",
       " ('quickli', 3082),\n",
       " ('except', 1330),\n",
       " ('boast', 457),\n",
       " ('aw', 283),\n",
       " ('pickl', 2884),\n",
       " ('side', 3494),\n",
       " ('dish', 1120),\n",
       " ('poorli', 2939),\n",
       " ('dull', 1191),\n",
       " ('unkempt', 4079),\n",
       " ('fall', 1386),\n",
       " ('apart', 183),\n",
       " ('repair', 3224),\n",
       " ('repaint', 3223),\n",
       " ('outsid', 2739),\n",
       " ('bird', 430),\n",
       " ('ac', 16),\n",
       " ('bedsheet', 382),\n",
       " ('posit', 2953),\n",
       " ('co', 739),\n",
       " ('ordin', 2720),\n",
       " ('bill', 424),\n",
       " ('someon', 3580),\n",
       " ('kind', 2108),\n",
       " ('wholesom', 4282),\n",
       " ('discern', 1106),\n",
       " ('dine', 1090),\n",
       " ('housekeep', 1847),\n",
       " ('concierg', 815),\n",
       " ('return', 3267),\n",
       " ('dinner', 1093),\n",
       " ('pricey', 2997),\n",
       " ('amaz', 130),\n",
       " ('downsid', 1165),\n",
       " ('discolor', 1109),\n",
       " ('sink', 3516),\n",
       " ('ambianc', 133),\n",
       " ('tray', 3998),\n",
       " ('clear', 715),\n",
       " ('dissapoint', 1128),\n",
       " ('say', 3384),\n",
       " ('expens', 1349),\n",
       " ('tax', 3837),\n",
       " ('car', 570),\n",
       " ('taxi', 3838),\n",
       " ('greatli', 1666),\n",
       " ('anna', 162),\n",
       " ('salai', 3347),\n",
       " ('lunch', 2290),\n",
       " ('cost', 887),\n",
       " ('expect', 1347),\n",
       " ('presenc', 2984),\n",
       " ('vanakkam', 4152),\n",
       " ('perform', 2852),\n",
       " ('door', 1154),\n",
       " ('smile', 3554),\n",
       " ('complaint', 795),\n",
       " ('raintre', 3110),\n",
       " ('attent', 255),\n",
       " ('top', 3963),\n",
       " ('line', 2219),\n",
       " ('immacul', 1892),\n",
       " ('base', 344),\n",
       " ('visitor', 4205),\n",
       " ('appreci', 200),\n",
       " ('dustbin', 1199),\n",
       " ('wc', 4249),\n",
       " ('ventil', 4169),\n",
       " ('perman', 2857),\n",
       " ('pleas', 2907),\n",
       " ('adjust', 55),\n",
       " ('fairli', 1384),\n",
       " ('kettl', 2083),\n",
       " ('condit', 820),\n",
       " ('upto', 4117),\n",
       " ('lemon', 2202),\n",
       " ('tree', 4002),\n",
       " ('standard', 3679),\n",
       " ('far', 1395),\n",
       " ('mayb', 2378),\n",
       " ('overpr', 2752),\n",
       " ('satisfi', 3375),\n",
       " ('date', 984),\n",
       " ('router', 3316),\n",
       " ('sub', 3741),\n",
       " ('age', 76),\n",
       " ('heavi', 1749),\n",
       " ('usag', 4122),\n",
       " ('toll', 3955),\n",
       " ('major', 2317),\n",
       " ('chain', 619),\n",
       " ('smoke', 3555),\n",
       " ('term', 3869),\n",
       " ('hygien', 1867),\n",
       " ('compar', 788),\n",
       " ('higher', 1775),\n",
       " ('oper', 2706),\n",
       " ('class', 702),\n",
       " ('leman', 2201),\n",
       " ('henc', 1762),\n",
       " ('railway', 3106),\n",
       " ('station', 3688),\n",
       " ('compani', 787),\n",
       " ('air', 87),\n",
       " ('uncomfort', 4051),\n",
       " ('sleep', 3537),\n",
       " ('difficult', 1082),\n",
       " ('imagin', 1891),\n",
       " ('washroom', 4237),\n",
       " ('bare', 339),\n",
       " ('move', 2493),\n",
       " ('around', 217),\n",
       " ('truli', 4014),\n",
       " ('absolut', 12),\n",
       " ('total', 3966),\n",
       " ('wast', 4241),\n",
       " ('allot', 110),\n",
       " ('mark', 2351),\n",
       " ('fruit', 1548),\n",
       " ('moreov', 2480),\n",
       " ('match', 2366),\n",
       " ('see', 3413),\n",
       " ('photo', 2874),\n",
       " ('reduc', 3173),\n",
       " ('doubt', 1163),\n",
       " ('quiet', 3083),\n",
       " ('averag', 277),\n",
       " ('spa', 3608),\n",
       " ('wish', 4294),\n",
       " ('behaviour', 390),\n",
       " ('drink', 1179),\n",
       " ('equal', 1285),\n",
       " ('conveni', 860),\n",
       " ('rail', 3104),\n",
       " ('prompt', 3032),\n",
       " ('aroma', 215),\n",
       " ('compris', 806),\n",
       " ('abl', 5),\n",
       " ('asko', 236),\n",
       " ('away', 288),\n",
       " ('hospit', 1829),\n",
       " ('pay', 2827),\n",
       " ('short', 3480),\n",
       " ('costli', 888),\n",
       " ('schedul', 3389),\n",
       " ('type', 4029),\n",
       " ('feedback', 1418),\n",
       " ('format', 1503),\n",
       " ('somewhat', 3585),\n",
       " ('sorri', 3596),\n",
       " ('late', 2169),\n",
       " ('repli', 3233),\n",
       " ('actual', 43),\n",
       " ('india', 1921),\n",
       " ('four', 1513),\n",
       " ('mislead', 2448),\n",
       " ('hilton', 1785),\n",
       " ('worker', 4309),\n",
       " ('shout', 3482),\n",
       " ('disturb', 1135),\n",
       " ('box', 483),\n",
       " ('tick', 3927),\n",
       " ('break', 491),\n",
       " ('fast', 1400),\n",
       " ('mr', 2496),\n",
       " ('dinesh', 1091),\n",
       " ('assist', 242),\n",
       " ('till', 3935),\n",
       " ('period', 2854),\n",
       " ('vacat', 4141),\n",
       " ('somewher', 3586),\n",
       " ('flight', 1469),\n",
       " ('path', 2819),\n",
       " ('adjac', 53),\n",
       " ('main', 2309),\n",
       " ('road', 3296),\n",
       " ('lorri', 2267),\n",
       " ('driver', 1182),\n",
       " ('horn', 1824),\n",
       " ('brake', 485),\n",
       " ('hyatt', 1864),\n",
       " ('week', 4258),\n",
       " ('primarili', 3001),\n",
       " ('wed', 4257),\n",
       " ('hold', 1803),\n",
       " ('unfortun', 4067),\n",
       " ('rooftop', 3305),\n",
       " ('open', 2705),\n",
       " ('pm', 2918),\n",
       " ('noisi', 2608),\n",
       " ('disco', 1108),\n",
       " ('music', 2513),\n",
       " ('full', 1553),\n",
       " ('volum', 4209),\n",
       " ('nowher', 2631),\n",
       " ('sit', 3521),\n",
       " ('avoid', 282),\n",
       " ('channai', 627),\n",
       " ('pitfal', 2892),\n",
       " ('support', 3780),\n",
       " ('lose', 2268),\n",
       " ('translat', 3990),\n",
       " ('anoth', 168),\n",
       " ('notch', 2621),\n",
       " ('decor', 1002),\n",
       " ('garment', 1582),\n",
       " ('industri', 1928),\n",
       " ('stun', 3735),\n",
       " ('quick', 3081),\n",
       " ('effici', 1231),\n",
       " ('complain', 794),\n",
       " ('let', 2206),\n",
       " ('eas', 1211),\n",
       " ('love', 2278),\n",
       " ('everyon', 1310),\n",
       " ('error', 1289),\n",
       " ('ambienc', 135),\n",
       " ('cater', 594),\n",
       " ('round', 3314),\n",
       " ('clock', 725),\n",
       " ('ensur', 1273),\n",
       " ('kudo', 2138),\n",
       " ('per', 2849),\n",
       " ('wherea', 4277),\n",
       " ('remain', 3207),\n",
       " ('live', 2232),\n",
       " ('hype', 1868),\n",
       " ('part', 2801),\n",
       " ('roof', 3304),\n",
       " ('flagship', 1459),\n",
       " ('fli', 1468),\n",
       " ('eleph', 1245),\n",
       " ('happen', 1722),\n",
       " ('weekend', 4259),\n",
       " ('guess', 1687),\n",
       " ('entri', 1280),\n",
       " ('excit', 1333),\n",
       " ('unparallel', 4089),\n",
       " ('transport', 3992),\n",
       " ('upcom', 4107),\n",
       " ('le', 2182),\n",
       " ('pocket', 2919),\n",
       " ('modern', 2461),\n",
       " ('feel', 1419),\n",
       " ('everybodi', 1308),\n",
       " ('treat', 4000),\n",
       " ('special', 3617),\n",
       " ('pungent', 3053),\n",
       " ('inform', 1937),\n",
       " ('alloc', 109),\n",
       " ('new', 2578),\n",
       " ('multipl', 2508),\n",
       " ('follow', 1485),\n",
       " ('prepar', 2982),\n",
       " ('wonder', 4302),\n",
       " ('reason', 3142),\n",
       " ('mine', 2432),\n",
       " ('xma', 4329),\n",
       " ('year', 4340),\n",
       " ('brilliant', 501),\n",
       " ('yard', 4336),\n",
       " ('town', 3976),\n",
       " ('squar', 3650),\n",
       " ('lucki', 2287),\n",
       " ('grade', 1658),\n",
       " ('superb', 3774),\n",
       " ('loft', 2248),\n",
       " ('convers', 862),\n",
       " ('poster', 2957),\n",
       " ('bright', 499),\n",
       " ('sunday', 3770),\n",
       " ('decid', 1000),\n",
       " ('guindi', 1693),\n",
       " ('cherish', 656),\n",
       " ('delight', 1025),\n",
       " ('splendid', 3637),\n",
       " ('five', 1451),\n",
       " ('sum', 3766),\n",
       " ('crisp', 933),\n",
       " ('centr', 610),\n",
       " ('wrong', 4326),\n",
       " ('continent', 854),\n",
       " ('subdu', 3742),\n",
       " ('stylish', 3738),\n",
       " ('pleasur', 2911),\n",
       " ('infin', 1934),\n",
       " ('leela', 2195),\n",
       " ('palac', 2770),\n",
       " ('target', 3826),\n",
       " ('exercis', 1340),\n",
       " ('atmospher', 250),\n",
       " ('calm', 557),\n",
       " ('stick', 3698),\n",
       " ('bkhkhjuoipoioioi', 439),\n",
       " ('hkhghkhkhkjh', 1798),\n",
       " ('ghjggjhghggg', 1609),\n",
       " ('sad', 3335),\n",
       " ('polici', 2925),\n",
       " ('com', 762),\n",
       " ('valid', 4147),\n",
       " ('directli', 1099),\n",
       " ('din', 1089),\n",
       " ('hall', 1709),\n",
       " ('saw', 3383),\n",
       " ('upkeep', 4110),\n",
       " ('confirm', 826),\n",
       " ('record', 3165),\n",
       " ('ceil', 603),\n",
       " ('prefer', 2978),\n",
       " ('brighter', 500),\n",
       " ('cosi', 886),\n",
       " ('funtion', 1560),\n",
       " ('pressur', 2988),\n",
       " ('respons', 3254),\n",
       " ('miss', 2451),\n",
       " ('formal', 1502),\n",
       " ('repres', 3235),\n",
       " ('surround', 3789),\n",
       " ('hr', 1849),\n",
       " ('requir', 3238),\n",
       " ('upgrad', 4109),\n",
       " ('strongli', 3728),\n",
       " ('market', 2353),\n",
       " ('center', 607),\n",
       " ('play', 2903),\n",
       " ('design', 1052),\n",
       " ('gentl', 1595),\n",
       " ('skill', 3532),\n",
       " ('foreign', 1497),\n",
       " ('order', 2718),\n",
       " ('fish', 1449),\n",
       " ('fri', 1536),\n",
       " ('damag', 973),\n",
       " ('home', 1808),\n",
       " ('environ', 1282),\n",
       " ('honour', 1819),\n",
       " ('southern', 3604),\n",
       " ('favourit', 1407),\n",
       " ('delay', 1019),\n",
       " ('initi', 1943),\n",
       " ('third', 3904),\n",
       " ('graciou', 1657),\n",
       " ('run', 3324),\n",
       " ('pictur', 2886),\n",
       " ('walkabl', 4223),\n",
       " ('distanc', 1131),\n",
       " ('downstair', 1166),\n",
       " ('whenev', 4275),\n",
       " ('afford', 72),\n",
       " ('sapc', 3363),\n",
       " ('procedur', 3021),\n",
       " ('ad', 44),\n",
       " ('zone', 4359),\n",
       " ('game', 1573),\n",
       " ('alon', 115),\n",
       " ('memor', 2395),\n",
       " ('congest', 831),\n",
       " ('may', 2376),\n",
       " ('econom', 1220),\n",
       " ('st', 3661),\n",
       " ('march', 2347),\n",
       " ('nestl', 2572),\n",
       " ('meet', 2391),\n",
       " ('attach', 252),\n",
       " ('strateg', 3718),\n",
       " ('face', 1375),\n",
       " ('challeng', 621),\n",
       " ('blossom', 451),\n",
       " ('fulli', 1554),\n",
       " ('furnish', 1562),\n",
       " ('serf', 3431),\n",
       " ('boon', 471),\n",
       " ('viabl', 4186),\n",
       " ('factor', 1379),\n",
       " ('privaci', 3009),\n",
       " ('member', 2393),\n",
       " ('child', 667),\n",
       " ('pass', 2808),\n",
       " ('leisur', 2197),\n",
       " ('stroll', 3726),\n",
       " ('grind', 1674),\n",
       " ('behav', 388),\n",
       " ('sober', 3565),\n",
       " ('issu', 2000),\n",
       " ('annoy', 167),\n",
       " ('control', 859),\n",
       " ('panel', 2783),\n",
       " ('certain', 616),\n",
       " ('item', 2007),\n",
       " ('condition', 821),\n",
       " ('heater', 1747),\n",
       " ('cold', 751),\n",
       " ('iam', 1871),\n",
       " ('frequent', 1530),\n",
       " ('v', 4137),\n",
       " ('meter', 2411),\n",
       " ('simpli', 3511),\n",
       " ('md', 2380),\n",
       " ('crowd', 939),\n",
       " ('narrow', 2537),\n",
       " ('vehicl', 4166),\n",
       " ('gate', 1584),\n",
       " ('entranc', 1279),\n",
       " ('marina', 2350),\n",
       " ('beach', 365),\n",
       " ('okay', 2677),\n",
       " ('peac', 2836),\n",
       " ('inn', 1944),\n",
       " ('address', 50),\n",
       " ('track', 3979),\n",
       " ('addr', 49),\n",
       " ('impropp', 1903),\n",
       " ('brother', 505),\n",
       " ('admiss', 57),\n",
       " ('bigger', 421),\n",
       " ('do', 1141),\n",
       " ('whatev', 4272),\n",
       " ('websit', 4256),\n",
       " ('real', 3138),\n",
       " ('tour', 3971),\n",
       " ('anyway', 181),\n",
       " ('budget', 516),\n",
       " ('hope', 1822),\n",
       " ('septemb', 3429),\n",
       " ('tidi', 3929),\n",
       " ('aircon', 88),\n",
       " ('cool', 872),\n",
       " ('tramp', 3986),\n",
       " ('street', 3720),\n",
       " ('thailand', 3881),\n",
       " ('forward', 1511),\n",
       " ('tell', 3857),\n",
       " ('muslim', 2514),\n",
       " ('alcohol', 103),\n",
       " ('strictli', 3724),\n",
       " ('forbid', 1494),\n",
       " ('western', 4267),\n",
       " ('across', 37),\n",
       " ('impress', 1901),\n",
       " ('local', 2240),\n",
       " ('pretti', 2989),\n",
       " ('admit', 58),\n",
       " ('rebat', 3144),\n",
       " ('inr', 1946),\n",
       " ('anyon', 177),\n",
       " ('mid', 2420),\n",
       " ('conjunct', 833),\n",
       " ('north', 2618),\n",
       " ('middl', 2422),\n",
       " ('appoint', 198),\n",
       " ('shabbi', 3451),\n",
       " ('neighbourhood', 2569),\n",
       " ('dodgi', 1144),\n",
       " ('ananda', 156),\n",
       " ('bhawan', 416),\n",
       " ('approach', 203),\n",
       " ('doesnt', 1145),\n",
       " ('matter', 2371),\n",
       " ('summer', 3767),\n",
       " ('fan', 1391),\n",
       " ('c', 549),\n",
       " ('useabl', 4126),\n",
       " ('consid', 839),\n",
       " ('tasti', 3832),\n",
       " ('mosquito', 2485),\n",
       " ('repel', 3228),\n",
       " ('anywher', 182),\n",
       " ('fashion', 1399),\n",
       " ('coffe', 747),\n",
       " ('colleagu', 755),\n",
       " ('itali', 2002),\n",
       " ('furnitur', 1563),\n",
       " ('ihom', 1884),\n",
       " ('system', 3803),\n",
       " ('compat', 790),\n",
       " ('current', 957),\n",
       " ('iphon', 1985),\n",
       " ('ipad', 1984),\n",
       " ('radisson', 3098),\n",
       " ('benefit', 400),\n",
       " ('proxim', 3044),\n",
       " ('traffic', 3982),\n",
       " ('clutter', 736),\n",
       " ('although', 125),\n",
       " ('readi', 3136),\n",
       " ('bodhi', 459),\n",
       " ('start', 3684),\n",
       " ('fulfil', 1552),\n",
       " ('holiday', 1806),\n",
       " ('pickup', 2885),\n",
       " ('pre', 2976),\n",
       " ('precomput', 2977),\n",
       " ('registr', 3190),\n",
       " ('key', 2084),\n",
       " ('weaker', 4252),\n",
       " ('nearer', 2549),\n",
       " ('wit', 4295),\n",
       " ('costlier', 889),\n",
       " ('bathtub', 357),\n",
       " ('shall', 3453),\n",
       " ('verynic', 4179),\n",
       " ('antast', 171),\n",
       " ('low', 2280),\n",
       " ('raddison', 3094),\n",
       " ('fell', 1420),\n",
       " ('poll', 2928),\n",
       " ('pa', 2760),\n",
       " ('fflhlxoxoxitxtxttcolgtcoxgxtixkrxrxfllxdridxfizgxoxixxtoxothcgchochcypyfcycoycyycyycpufotdtodtodotxyycpycyxpgxgpxyoxtoxpyxttxylhxpxphxogxttxxoh',\n",
       "  1431),\n",
       " ('gcocgxggcogctcoggxotxoyxyxyocicotxotxxotxpyxyoxyoxoyxttxtixttxxhxoyyxxdypxyocyycogcxoxoycyycoyh',\n",
       "  1589),\n",
       " ('courtesi', 906),\n",
       " ('clarifi', 699),\n",
       " ('immedi', 1893),\n",
       " ('cloth', 731),\n",
       " ('hang', 1717),\n",
       " ('enumer', 1281),\n",
       " ('confus', 829),\n",
       " ('helpful', 1758),\n",
       " ('chauffeur', 639),\n",
       " ('foot', 1491),\n",
       " ('massag', 2360),\n",
       " ('transfer', 3988),\n",
       " ('unwind', 4106),\n",
       " ('receptionist', 3152),\n",
       " ('unclean', 4049),\n",
       " ('plate', 2902),\n",
       " ...]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countVec = CountVectorizer(analyzer=text_processing)\n",
    "countVec.fit(temp[\"Review_Text\"])\n",
    "list(countVec.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          term  occurrences\n",
      "0          aaa            1\n",
      "1     aadithya            2\n",
      "2          aap            1\n",
      "3        abdul            1\n",
      "4        abhay            1\n",
      "...        ...          ...\n",
      "4359      zone            6\n",
      "4360       zoo            1\n",
      "4361         Â¹            1\n",
      "4362         Ã¢            1\n",
      "4363  Ã©conomiq            1\n",
      "\n",
      "[4364 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>occurrences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1837</th>\n",
       "      <td>hotel</td>\n",
       "      <td>4813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>good</td>\n",
       "      <td>4345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3306</th>\n",
       "      <td>room</td>\n",
       "      <td>3198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3691</th>\n",
       "      <td>stay</td>\n",
       "      <td>2317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3439</th>\n",
       "      <td>servic</td>\n",
       "      <td>1688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3666</th>\n",
       "      <td>staff</td>\n",
       "      <td>1645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>food</td>\n",
       "      <td>1556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>locat</td>\n",
       "      <td>1426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2592</th>\n",
       "      <td>nice</td>\n",
       "      <td>976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>breakfast</td>\n",
       "      <td>948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>clean</td>\n",
       "      <td>945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>place</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>great</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>also</td>\n",
       "      <td>705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>excel</td>\n",
       "      <td>604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>chennai</td>\n",
       "      <td>604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3936</th>\n",
       "      <td>time</td>\n",
       "      <td>585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>facil</td>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>experi</td>\n",
       "      <td>547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2745</th>\n",
       "      <td>overal</td>\n",
       "      <td>530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>help</td>\n",
       "      <td>525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>money</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3042</th>\n",
       "      <td>provid</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2696</th>\n",
       "      <td>one</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>like</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>need</td>\n",
       "      <td>479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>restaur</td>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4265</th>\n",
       "      <td>well</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>check</td>\n",
       "      <td>459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4322</th>\n",
       "      <td>would</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>get</td>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3162</th>\n",
       "      <td>recommend</td>\n",
       "      <td>404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4149</th>\n",
       "      <td>valu</td>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>friendli</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4204</th>\n",
       "      <td>visit</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2546</th>\n",
       "      <td>near</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>comfort</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>day</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4308</th>\n",
       "      <td>work</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>busi</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>book</td>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3140</th>\n",
       "      <td>realli</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>citi</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>best</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3071</th>\n",
       "      <td>qualiti</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2319</th>\n",
       "      <td>make</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4031</th>\n",
       "      <td>u</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>airport</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>avail</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2596</th>\n",
       "      <td>night</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>travel</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>enjoy</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>famili</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>go</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>bathroom</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>improv</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>price</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>even</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>bad</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>close</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           term  occurrences\n",
       "1837      hotel         4813\n",
       "1636       good         4345\n",
       "3306       room         3198\n",
       "3691       stay         2317\n",
       "3439     servic         1688\n",
       "3666      staff         1645\n",
       "1487       food         1556\n",
       "2242      locat         1426\n",
       "2592       nice          976\n",
       "492   breakfast          948\n",
       "708       clean          945\n",
       "2895      place          720\n",
       "1664      great          718\n",
       "121        also          705\n",
       "1328      excel          604\n",
       "653     chennai          604\n",
       "3936       time          585\n",
       "1377      facil          576\n",
       "1350     experi          547\n",
       "2745     overal          530\n",
       "1756       help          525\n",
       "2475      money          510\n",
       "3042     provid          506\n",
       "2696        one          492\n",
       "2217       like          491\n",
       "2558       need          479\n",
       "3258    restaur          476\n",
       "4265       well          473\n",
       "645       check          459\n",
       "4322      would          435\n",
       "1603        get          426\n",
       "3162  recommend          404\n",
       "4149       valu          401\n",
       "1540   friendli          399\n",
       "4204      visit          395\n",
       "2546       near          394\n",
       "769     comfort          388\n",
       "987         day          376\n",
       "4308       work          374\n",
       "537        busi          356\n",
       "469        book          353\n",
       "3140     realli          351\n",
       "696        citi          337\n",
       "406        best          326\n",
       "3071    qualiti          325\n",
       "2319       make          324\n",
       "4031          u          321\n",
       "92      airport          320\n",
       "273       avail          307\n",
       "2596      night          304\n",
       "3996     travel          297\n",
       "1269      enjoy          296\n",
       "1388     famili          295\n",
       "1627         go          280\n",
       "352    bathroom          279\n",
       "1904     improv          273\n",
       "2993      price          273\n",
       "1303       even          271\n",
       "311         bad          268\n",
       "727       close          262"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countVec_count = countVec.transform(temp[\"Review_Text\"])\n",
    "\n",
    "#make array from number of occurrences\n",
    "occ = np.asarray(countVec_count.sum(axis=0)).ravel().tolist()\n",
    "\n",
    "#make a new data frame with columns term and occurrences, meaning word and number of occurences\n",
    "bowListFrame = pd.DataFrame({'term': countVec.get_feature_names(), 'occurrences': occ})\n",
    "print(bowListFrame)\n",
    "\n",
    "#sort in order of number of word occurences, most->least. if you leave of ascending flag should default ASC\n",
    "bowListFrame.sort_values(by='occurrences', ascending=False).head(60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "textTransformer = TfidfTransformer()\n",
    "textWeights = textTransformer.fit_transform(countVec_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          term    weight\n",
      "0          aaa  0.000067\n",
      "1     aadithya  0.000116\n",
      "2          aap  0.000053\n",
      "3        abdul  0.000082\n",
      "4        abhay  0.000086\n",
      "...        ...       ...\n",
      "4359      zone  0.000451\n",
      "4360       zoo  0.000042\n",
      "4361         Â¹  0.000063\n",
      "4362         Ã¢  0.000063\n",
      "4363  Ã©conomiq  0.000125\n",
      "\n",
      "[4364 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>good</td>\n",
       "      <td>0.083791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837</th>\n",
       "      <td>hotel</td>\n",
       "      <td>0.075933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3306</th>\n",
       "      <td>room</td>\n",
       "      <td>0.052106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3691</th>\n",
       "      <td>stay</td>\n",
       "      <td>0.048487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3439</th>\n",
       "      <td>servic</td>\n",
       "      <td>0.037661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3666</th>\n",
       "      <td>staff</td>\n",
       "      <td>0.037209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>food</td>\n",
       "      <td>0.033517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>locat</td>\n",
       "      <td>0.032512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2592</th>\n",
       "      <td>nice</td>\n",
       "      <td>0.031078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>clean</td>\n",
       "      <td>0.027143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>breakfast</td>\n",
       "      <td>0.025835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>great</td>\n",
       "      <td>0.024977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>excel</td>\n",
       "      <td>0.022628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>place</td>\n",
       "      <td>0.021375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>also</td>\n",
       "      <td>0.020541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>experi</td>\n",
       "      <td>0.019017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>facil</td>\n",
       "      <td>0.018094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>help</td>\n",
       "      <td>0.017994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2745</th>\n",
       "      <td>overal</td>\n",
       "      <td>0.017800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>comfort</td>\n",
       "      <td>0.017766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           term    weight\n",
       "1636       good  0.083791\n",
       "1837      hotel  0.075933\n",
       "3306       room  0.052106\n",
       "3691       stay  0.048487\n",
       "3439     servic  0.037661\n",
       "3666      staff  0.037209\n",
       "1487       food  0.033517\n",
       "2242      locat  0.032512\n",
       "2592       nice  0.031078\n",
       "708       clean  0.027143\n",
       "492   breakfast  0.025835\n",
       "1664      great  0.024977\n",
       "1328      excel  0.022628\n",
       "2895      place  0.021375\n",
       "121        also  0.020541\n",
       "1350     experi  0.019017\n",
       "1377      facil  0.018094\n",
       "1756       help  0.017994\n",
       "2745     overal  0.017800\n",
       "769     comfort  0.017766"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#follow similar process to making new data frame with word occurrences, but with term weights\n",
    "textWeightsFin = np.asarray(textWeights.mean(axis=0)).ravel().tolist()\n",
    "\n",
    "#now that we've done Tfid, make a dataframe with weights and names\n",
    "textWeightFrame = pd.DataFrame({'term': countVec.get_feature_names(), 'weight': textWeightsFin})\n",
    "print(textWeightFrame)\n",
    "textWeightFrame.sort_values(by='weight', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "\n",
    "space={'max_depth': hp.quniform(\"max_depth\", 3, 18, 1),\n",
    "        'gamma': hp.uniform ('gamma', 1,9),\n",
    "        'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n",
    "        'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n",
    "        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "        'n_estimators': 180,\n",
    "        'seed': 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = temp['Review_Text']\n",
    "y = temp['Sentiment']\n",
    "\n",
    "#test = test_tweets['post']\n",
    "from sklearn.model_selection import train_test_split\n",
    "msg_train, msg_test, label_train, label_test = train_test_split(temp['Review_Text'], temp['Sentiment'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(space):\n",
    "    \n",
    "    clf=xgb.XGBClassifier(\n",
    "                    n_estimators =space['n_estimators'], max_depth = int(space['max_depth']), gamma = space['gamma'],\n",
    "                    reg_alpha = int(space['reg_alpha']),min_child_weight=int(space['min_child_weight']),\n",
    "                    colsample_bytree=int(space['colsample_bytree']))\n",
    "    \n",
    "    evaluation = [( msg_train, label_train), ( msg_test, label_test)]\n",
    "    \n",
    "    clf.fit(msg_train, label_train,\n",
    "            eval_set=evaluation, eval_metric=\"auc\",\n",
    "            early_stopping_rounds=10,verbose=False)\n",
    "    \n",
    "\n",
    "    pred = clf.predict(msg_test)\n",
    "    accuracy = accuracy_score(test_y, pred>0.5)\n",
    "    print (\"SCORE:\", accuracy)\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                          | 0/100 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Pipeline.fit does not accept the eval_set parameter. You can pass parameters to specific steps of your pipeline using the stepname__parameter format, e.g. `Pipeline.fit(X, y, logisticregression__sample_weight=sample_weight)`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                          | 0/100 [00:00<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Pipeline.fit does not accept the eval_set parameter. You can pass parameters to specific steps of your pipeline using the stepname__parameter format, e.g. `Pipeline.fit(X, y, logisticregression__sample_weight=sample_weight)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-e948e57d088a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m best_hyperparams = fmin(fn = objective,\n\u001b[0m\u001b[0;32m      4\u001b[0m                         \u001b[0mspace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                         \u001b[0malgo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtpe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mallow_trials_fmin\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fmin\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 540\u001b[1;33m         return trials.fmin(\n\u001b[0m\u001b[0;32m    541\u001b[0m             \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m             \u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfmin\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfmin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m         return fmin(\n\u001b[0m\u001b[0;32m    672\u001b[0m             \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m             \u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m     \u001b[1;31m# next line is where the fmin is actually executed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    298\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m                     \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    176\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"job exception: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    890\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m             )\n\u001b[1;32m--> 892\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-dc4a5cb8e25b>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(space)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mevaluation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mmsg_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m \u001b[0mmsg_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     clf.fit(msg_train, label_train,\n\u001b[0m\u001b[0;32m     16\u001b[0m             \u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"auc\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             early_stopping_rounds=10,verbose=False)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    327\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         \"\"\"\n\u001b[1;32m--> 329\u001b[1;33m         \u001b[0mfit_params_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         with _print_elapsed_time('Pipeline',\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_check_fit_params\u001b[1;34m(self, **fit_params)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mpname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m'__'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    244\u001b[0m                     \u001b[1;34m\"Pipeline.fit does not accept the {} parameter. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m                     \u001b[1;34m\"You can pass parameters to specific steps of your \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Pipeline.fit does not accept the eval_set parameter. You can pass parameters to specific steps of your pipeline using the stepname__parameter format, e.g. `Pipeline.fit(X, y, logisticregression__sample_weight=sample_weight)`."
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective,\n",
    "                        space = space,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 100,\n",
    "                        trials = trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\navvu\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:47:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('bow',\n",
       "                 CountVectorizer(analyzer=<function text_processing at 0x0000020B7A939040>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('classifier',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, enable_categorical=False,\n",
       "                               gamma=0, gpu_id=-1, importance_type=None,\n",
       "                               interaction_constraints='',\n",
       "                               learning_rate=0.300000012, max_delta_step=0,\n",
       "                               max_depth=6, min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=100,\n",
       "                               n_jobs=8, num_parallel_tree=1,\n",
       "                               objective='multi:softprob', predictor='auto',\n",
       "                               random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                               scale_pos_weight=None, subsample=1,\n",
       "                               tree_method='exact', validate_parameters=1,\n",
       "                               verbosity=None))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Machine Learning Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_processing)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', xgb.XGBClassifier()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])\n",
    "pipeline.fit(msg_train,label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[ 48  13   8]\n",
      " [ 14  86  15]\n",
      " [ 28  68 660]]\n",
      "Accuracy Score\n",
      "0.8446808510638298\n"
     ]
    }
   ],
   "source": [
    "predictions = pipeline.predict(msg_test)\n",
    "\n",
    "# print(\"Classification report\")\n",
    "# print(classification_report(predictions,label_test))\n",
    "print (\"Confusion Matrix\")\n",
    "print(confusion_matrix(predictions,label_test))\n",
    "print(\"Accuracy Score\")\n",
    "print(accuracy_score(predictions,label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.70      0.60        69\n",
      "           2       0.51      0.75      0.61       115\n",
      "           3       0.97      0.87      0.92       756\n",
      "\n",
      "    accuracy                           0.84       940\n",
      "   macro avg       0.67      0.77      0.71       940\n",
      "weighted avg       0.88      0.84      0.86       940\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report\")\n",
    "print(classification_report(predictions,label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>I've made a booking with the help of Mr. Manoj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>I have been to this property in Jan 2022. Very...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Very good stay , loved the hospitality and war...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>I had booked Holiday Inn express for 2 days fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Excellent stay.. well maintained property.. ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1995</td>\n",
       "      <td>During kolkata office visit stayed at Golden t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1996</td>\n",
       "      <td>I was at the Golden Tulip for 5 days. And it w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1997</td>\n",
       "      <td>The hotel does not have a very prominent locat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1998</td>\n",
       "      <td>I had booked executive room, but the room prov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1999</td>\n",
       "      <td>The hotel is everything one can ask for, the r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0     I've made a booking with the help of Mr. Manoj...\n",
       "1     I have been to this property in Jan 2022. Very...\n",
       "2     Very good stay , loved the hospitality and war...\n",
       "3     I had booked Holiday Inn express for 2 days fo...\n",
       "4     Excellent stay.. well maintained property.. ve...\n",
       "...                                                 ...\n",
       "1995  During kolkata office visit stayed at Golden t...\n",
       "1996  I was at the Golden Tulip for 5 days. And it w...\n",
       "1997  The hotel does not have a very prominent locat...\n",
       "1998  I had booked executive room, but the room prov...\n",
       "1999  The hotel is everything one can ask for, the r...\n",
       "\n",
       "[2000 rows x 1 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('kolkata_reviews.csv',encoding='utf-8')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>I've made a booking with the help of Mr. Manoj...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>I have been to this property in Jan 2022. Very...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Very good stay , loved the hospitality and war...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>I had booked Holiday Inn express for 2 days fo...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Excellent stay.. well maintained property.. ve...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1995</td>\n",
       "      <td>During kolkata office visit stayed at Golden t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1996</td>\n",
       "      <td>I was at the Golden Tulip for 5 days. And it w...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1997</td>\n",
       "      <td>The hotel does not have a very prominent locat...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1998</td>\n",
       "      <td>I had booked executive room, but the room prov...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1999</td>\n",
       "      <td>The hotel is everything one can ask for, the r...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text Sentiment\n",
       "0     I've made a booking with the help of Mr. Manoj...         3\n",
       "1     I have been to this property in Jan 2022. Very...         3\n",
       "2     Very good stay , loved the hospitality and war...         3\n",
       "3     I had booked Holiday Inn express for 2 days fo...         3\n",
       "4     Excellent stay.. well maintained property.. ve...         3\n",
       "...                                                 ...       ...\n",
       "1995  During kolkata office visit stayed at Golden t...         3\n",
       "1996  I was at the Golden Tulip for 5 days. And it w...         3\n",
       "1997  The hotel does not have a very prominent locat...         3\n",
       "1998  I had booked executive room, but the room prov...         3\n",
       "1999  The hotel is everything one can ask for, the r...         3\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment']=predictions\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    2000\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
